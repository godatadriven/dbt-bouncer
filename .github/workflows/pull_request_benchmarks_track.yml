name: Pull Request Benchmarks Track

on:
  workflow_run:
    workflows: [CI pipeline]
    types: [completed]

env:
    BENCHMARK_RESULTS: benchmark_results.json
    PR_EVENT: event.json

jobs:
  track_fork_pr_branch:
    if: github.event.workflow_run.conclusion == 'success'
    permissions:
      pull-requests: write
    runs-on: ubuntu-22.04
    steps:
      - name: Download Benchmark Results
        uses: dawidd6/action-download-artifact@v6
        with:
          name: ${{ env.BENCHMARK_RESULTS }}
          run_id: ${{ github.event.workflow_run.id }}

      - name: Download PR Event
        uses: dawidd6/action-download-artifact@v6
        with:
          name: ${{ env.PR_EVENT }}
          run_id: ${{ github.event.workflow_run.id }}

      - name: Export PR Event Data
        uses: actions/github-script@v8
        with:
          script: |
            let fs = require('fs');
            let prEvent = JSON.parse(fs.readFileSync(process.env.PR_EVENT, {encoding: 'utf8'}));
            core.exportVariable("PR_HEAD", prEvent.pull_request.head.ref);
            core.exportVariable("PR_HEAD_SHA", prEvent.pull_request.head.sha);
            core.exportVariable("PR_BASE", prEvent.pull_request.base.ref);
            core.exportVariable("PR_BASE_SHA", prEvent.pull_request.base.sha);
            core.exportVariable("PR_NUMBER", prEvent.number);

      - uses: bencherdev/bencher@v0.5.10

      - name: Track Benchmarks with Bencher
        run: |
          bencher run \
            --adapter shell_hyperfine \
            --branch "$PR_HEAD" \
            --ci-number "$PR_NUMBER" \
            --err \
            --file "$BENCHMARK_RESULTS" \
            --github-actions '${{ secrets.GITHUB_TOKEN }}' \
            --hash "$PR_HEAD_SHA" \
            --project dbt-bouncer \
            --start-point "$GITHUB_BASE_REF" \
            --start-point-hash 'ade4e6321b2d9865f461e9baebcdfb8b1153acda' \
            --start-point-clone-thresholds \
            --start-point-reset \
            --testbed ubuntu-2204 \
            --threshold-max-sample-size 16 \
            --threshold-measure latency \
            --threshold-test percentage \
            --threshold-upper-boundary 0.1 \
            --thresholds-reset \
            --token '${{ secrets.BENCHER_API_TOKEN }}'
